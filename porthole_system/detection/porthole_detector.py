#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
í¬íŠ¸í™€ ê°ì§€ ëª¨ë“ˆ (Porthole Detection Module)

ì´ ëª¨ë“ˆì€ ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ë°ì´í„°ë¡œë¶€í„° í¬íŠ¸í™€ì„ ê°ì§€í•˜ê³ 
ê¹Šì´ë¥¼ ì¶”ì •í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. YOLOv5ë¥¼ ì‚¬ìš©í•œ í¬íŠ¸í™€ ê°ì²´ íƒì§€
2. MiDaSë¥¼ ì‚¬ìš©í•œ ê¹Šì´ ì¶”ì •
3. ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
"""

import os
import cv2
import numpy as np
import torch
import pathlib
import time
import math
from typing import Dict, List, Optional, Tuple, Union, Any, Set

# Windows ê²½ë¡œ í˜¸í™˜ì„±ì„ ìœ„í•œ ì„¤ì •
temp = pathlib.WindowsPath
pathlib.WindowsPath = pathlib.PosixPath

# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from config_utils import get_global_config, get_nested_value
from server_api import PortholeServerAPI

# ëª¨ë¸ ë° ê´€ë ¨ ë³€ìˆ˜ ì´ˆê¸°í™” (íƒ€ì… íŒíŠ¸ ì¶”ê°€)
yolo_model: Optional[Any] = None
midas: Optional[Any] = None
transform: Optional[Any] = None
device: Optional[torch.device] = None


class PortholeDetector:
    """í¬íŠ¸í™€ ê°ì§€ ë° ì²˜ë¦¬ë¥¼ ìœ„í•œ í´ë˜ìŠ¤ (ì‹¤ì‹œê°„ ì›¹ìº  ì „ìš©)"""
    
    def __init__(self, config: Optional[Dict] = None, server_api: Optional[PortholeServerAPI] = None):
        """
        PortholeDetector ì´ˆê¸°í™”
        
        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬ (Noneì´ë©´ ì „ì—­ ì„¤ì • ì‚¬ìš©)
            server_api: PortholeServerAPI ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ìƒˆë¡œ ìƒì„±)
        """
        self.config = config or get_global_config()
        
        # YOLO ëª¨ë¸ ì„¤ì •
        self.model_path = get_nested_value(self.config, 'models.yolo.path', 
                                         'yolov5/runs/train/gun_yolov5s_results/weights/best.pt')
        self.confidence_threshold = get_nested_value(self.config, 'models.yolo.confidence_threshold', 0.5)
        self.img_size = get_nested_value(self.config, 'models.yolo.img_size', 416)
        
        # MiDaS ëª¨ë¸ ì„¤ì •
        self.midas_model_type = get_nested_value(self.config, 'models.midas.model_type', "DPT_Hybrid")
        self.midas_transform_type = get_nested_value(self.config, 'models.midas.transform_type', "small_transform")
        
        # ê¹Šì´ ë¶„ë¥˜ ì„ê³„ê°’
        self.shallow_threshold = get_nested_value(self.config, 'depth_classification.shallow_threshold', 500)
        self.medium_threshold = get_nested_value(self.config, 'depth_classification.medium_threshold', 1500)
        
        # ê°ì§€ ì„¤ì •
        self.min_detection_confidence = get_nested_value(self.config, 'detection.min_detection_confidence', 0.3)
        self.send_to_server_confidence = get_nested_value(self.config, 'detection.send_to_server_confidence', 0.5)
        
        # ì¤‘ë³µ ì „ì†¡ ë°©ì§€ ì„¤ì •
        self.min_send_interval = get_nested_value(self.config, 'detection.min_send_interval', 5.0)
        self.position_tolerance = get_nested_value(self.config, 'detection.position_tolerance', 0.0001)
        self.max_sent_cache_size = get_nested_value(self.config, 'detection.max_sent_cache_size', 100)
        self.duplicate_detection_distance = get_nested_value(self.config, 'detection.duplicate_detection_distance', 50)
        
        # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ ë‚´ë¶€ ìƒíƒœ
        self.last_send_time = 0
        self.recent_detections: List[Dict] = []  # ìµœê·¼ ê°ì§€ëœ í¬íŠ¸í™€ë“¤
        self.sent_locations: Set[Tuple[float, float]] = set()  # ì „ì†¡ëœ ìœ„ì¹˜ë“¤
        
        # ì„œë²„ API ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë˜ëŠ” ì „ë‹¬ë°›ì€ ê²ƒ ì‚¬ìš©
        self.server_api = server_api if server_api else PortholeServerAPI(self.config)
        
        # ì‹œê°í™” ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
        vis_config = self.config.get('visualization', {})
        self.class_colors = vis_config.get('class_colors', {
            'shallow': [0, 255, 0],
            'medium': [0, 165, 255], 
            'deep': [0, 0, 255]
        })
        self.text_size = vis_config.get('text_size', 0.6)
        self.text_thickness = vis_config.get('text_thickness', 2)
        self.box_thickness = vis_config.get('box_thickness', 2)
        self.overlay_alpha = vis_config.get('overlay_alpha', 0.4)
        
        # ìœ„ì¹˜ ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
        location_config = self.config.get('location', {})
        self.default_lat = location_config.get('latitude', 37.5665)
        self.default_lng = location_config.get('longitude', 126.9780)
        
        # ë””ë²„ê·¸ ì„¤ì •
        debug_config = self.config.get('debug', {})
        self.print_detections = debug_config.get('print_detections', True)
        self.print_model_loading = debug_config.get('print_model_loading', True)
        
    def _get_device(self) -> torch.device:
        """
        ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        
        Returns:
            torch.device: ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤
        """
        device_config = self.config.get('device', {})
        
        # CPU ê°•ì œ ì‚¬ìš© ì„¤ì •ì´ ìˆìœ¼ë©´ CPU ì‚¬ìš©
        if device_config.get('force_cpu', False):
            return torch.device("cpu")
        
        # Apple Silicon (M1/M2) MPS ì§€ì› í™•ì¸
        if device_config.get('use_mps', True) and torch.backends.mps.is_available():
            return torch.device("mps")
        
        # NVIDIA CUDA ì§€ì› í™•ì¸
        if device_config.get('use_cuda', True) and torch.cuda.is_available():
            return torch.device("cuda")
        
        # ê¸°ë³¸ì ìœ¼ë¡œ CPU ì‚¬ìš©
        return torch.device("cpu")
        
    def load_models(self) -> bool:
        """
        YOLOv5ì™€ MiDaS ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Returns:
            bool: ëª¨ë¸ ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        global yolo_model, midas, transform, device

        if yolo_model is not None and midas is not None:
            return True  # ì´ë¯¸ ëª¨ë¸ì´ ë¡œë“œë˜ì—ˆìœ¼ë©´ ë‹¤ì‹œ ë¡œë“œí•˜ì§€ ì•ŠìŒ

        try:
            if self.print_model_loading:
                print("í¬íŠ¸í™€ ê°ì§€ ë° ê¹Šì´ ì¶”ì • ëª¨ë¸ ë¡œë“œ ì¤‘...")

            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            device = self._get_device()
            if self.print_model_loading:
                print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

            # ì»¤ìŠ¤í…€ í•™ìŠµëœ YOLOv5 ëª¨ë¸ ë¡œë“œ (í¬íŠ¸í™€ íƒì§€ìš©)
            if not os.path.exists(self.model_path):
                print(f"âš ï¸  YOLO ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
                print("ê¸°ë³¸ YOLOv5s ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')
            else:
                yolo_model = torch.hub.load('ultralytics/yolov5', 'custom', path=self.model_path)
            
            yolo_model.conf = self.confidence_threshold  # ì‹ ë¢°ë„ ì„ê³„ê°’ ì„¤ì •
            yolo_model.img_size = self.img_size  # ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •
            yolo_model.to(device)
            yolo_model.eval()

            # MiDaS ëª¨ë¸ ë¡œë“œ (ê¹Šì´ ì¶”ì •ìš©)
            midas = torch.hub.load("intel-isl/MiDaS", self.midas_model_type)
            midas.to(device)
            midas.eval()
            
            # MiDaS ì…ë ¥ ì´ë¯¸ì§€ ë³€í™˜ í•¨ìˆ˜ ë¡œë”©
            midas_transforms = torch.hub.load("intel-isl/MiDaS", "transforms")
            
            # transform íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ ë³€í™˜ ì„ íƒ
            try:
                if self.midas_transform_type == "small_transform":
                    transform = midas_transforms.small_transform
                elif self.midas_transform_type == "dpt_transform":
                    transform = midas_transforms.dpt_transform  
                else:
                    # ê¸°ë³¸ê°’ìœ¼ë¡œ small_transform ì‚¬ìš©
                    transform = midas_transforms.small_transform
                    if self.print_model_loading:
                        print(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ë³€í™˜ íƒ€ì…: {self.midas_transform_type}, small_transform ì‚¬ìš©")
            except AttributeError:
                # ì†ì„±ì— ì ‘ê·¼í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
                transform = midas_transforms.small_transform
                if self.print_model_loading:
                    print(f"âš ï¸  ë³€í™˜ í•¨ìˆ˜ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ë³€í™˜ ì‚¬ìš©")

            if self.print_model_loading:
                print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì¥ì¹˜: {device})")
            return True

        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    def _classify_depth(self, depth_value: float) -> Tuple[str, List[int]]:
        """
        ê¹Šì´ê°’ì— ë”°ë¼ ë¶„ë¥˜í•˜ê³  í•´ë‹¹í•˜ëŠ” ìƒ‰ìƒì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Args:
            depth_value: ê¹Šì´ê°’
            
        Returns:
            (ë¶„ë¥˜ëª…, BGR ìƒ‰ìƒ)
        """
        if depth_value < self.shallow_threshold:
            return "shallow", self.class_colors['shallow']
        elif depth_value < self.medium_threshold:
            return "medium", self.class_colors['medium']
        else:
            return "deep", self.class_colors['deep']
    
    def _is_duplicate_position(self, lat: float, lng: float) -> bool:
        """
        ì´ë¯¸ ì „ì†¡ëœ ìœ„ì¹˜ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        
        Args:
            lat: ìœ„ë„
            lng: ê²½ë„
            
        Returns:
            bool: ì¤‘ë³µ ìœ„ì¹˜ ì—¬ë¶€
        """
        for sent_lat, sent_lng in self.sent_locations:
            if (abs(lat - sent_lat) < self.position_tolerance and 
                abs(lng - sent_lng) < self.position_tolerance):
                return True
        return False
    
    def _add_sent_position(self, lat: float, lng: float) -> None:
        """
        ì „ì†¡ëœ ìœ„ì¹˜ë¥¼ ìºì‹œì— ì¶”ê°€í•©ë‹ˆë‹¤.
        
        Args:
            lat: ìœ„ë„
            lng: ê²½ë„
        """
        # ìºì‹œ í¬ê¸° ì œí•œ
        if len(self.sent_locations) >= self.max_sent_cache_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±° (ê°„ë‹¨íˆ ì²« ë²ˆì§¸ í•­ëª© ì œê±°)
            self.sent_locations.pop()
        
        self.sent_locations.add((lat, lng))
    
    def _is_duplicate_detection(self, bbox: List[int]) -> bool:
        """
        í”„ë ˆì„ ë‚´ì—ì„œ ì¤‘ë³µ ê°ì§€ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        
        Args:
            bbox: ë°”ìš´ë”© ë°•ìŠ¤ [x1, y1, x2, y2]
            
        Returns:
            bool: ì¤‘ë³µ ê°ì§€ ì—¬ë¶€
        """
        x1, y1, x2, y2 = bbox
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        
        for detection in self.recent_detections:
            det_bbox = detection['bbox']
            det_x1, det_y1, det_x2, det_y2 = det_bbox
            det_center_x = (det_x1 + det_x2) / 2
            det_center_y = (det_y1 + det_y2) / 2
            
            # ê±°ë¦¬ ê³„ì‚°
            distance = math.sqrt((center_x - det_center_x)**2 + (center_y - det_center_y)**2)
            
            if distance < self.duplicate_detection_distance:
                return True
        
        return False
    
    def _should_send_to_server(self, pothole_infos: List[Dict]) -> Tuple[bool, Optional[Dict]]:
        """
        ì„œë²„ë¡œ ì „ì†¡í• ì§€ ê²°ì •í•˜ê³  ì „ì†¡í•  í¬íŠ¸í™€ì„ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            pothole_infos: ê°ì§€ëœ í¬íŠ¸í™€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            (ì „ì†¡ ì—¬ë¶€, ì„ íƒëœ í¬íŠ¸í™€ ì •ë³´)
        """
        current_time = time.time()
        
        # ìµœì†Œ ì „ì†¡ ê°„ê²© í™•ì¸
        if current_time - self.last_send_time < self.min_send_interval:
            return False, None
        
        # ì„œë²„ ì „ì†¡ ì„ê³„ê°’ ì´ìƒì˜ í¬íŠ¸í™€ë§Œ í•„í„°ë§
        high_confidence_potholes = [
            p for p in pothole_infos 
            if p['confidence'] >= self.send_to_server_confidence
        ]
        
        if not high_confidence_potholes:
            return False, None
        
        # ì¤‘ë³µ ìœ„ì¹˜ê°€ ì•„ë‹Œ í¬íŠ¸í™€ë§Œ í•„í„°ë§
        new_potholes = []
        for pothole in high_confidence_potholes:
            if not self._is_duplicate_position(pothole['lat'], pothole['lng']):
                new_potholes.append(pothole)
        
        if not new_potholes:
            return False, None
        
        # ê°€ì¥ ì‹ ë¢°ë„ê°€ ë†’ì€ í¬íŠ¸í™€ ì„ íƒ
        best_pothole = max(new_potholes, key=lambda x: x['confidence'])
        
        return True, best_pothole
    
    def detect_from_frame(self, frame: np.ndarray) -> Tuple[bool, List[Dict], np.ndarray]:
        """
        í”„ë ˆì„ì—ì„œ í¬íŠ¸í™€ì„ ê°ì§€í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
        
        Args:
            frame: ì…ë ¥ ë¹„ë””ì˜¤ í”„ë ˆì„
            
        Returns:
            (ê°ì§€ ì—¬ë¶€, í¬íŠ¸í™€ ì •ë³´ ë¦¬ìŠ¤íŠ¸, ì‹œê°í™”ëœ í”„ë ˆì„)
        """
        # ëª¨ë¸ ë¡œë“œ í™•ì¸
        if not self.load_models():
            return False, [], frame
        
        # ì „ì—­ ë³€ìˆ˜ None ì²´í¬
        if yolo_model is None or midas is None or transform is None or device is None:
            print("âŒ ëª¨ë¸ì´ ì œëŒ€ë¡œ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False, [], frame

        try:
            # MiDaSë¡œ ê¹Šì´ ë§µ ìƒì„±
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            input_batch = transform(frame_rgb).to(device)
            
            with torch.no_grad():
                depth_pred = midas(input_batch)
                depth_map = torch.nn.functional.interpolate(
                    depth_pred.unsqueeze(1), size=frame.shape[:2],
                    mode="bicubic", align_corners=False
                ).squeeze().cpu().numpy()

            # YOLOv5ë¡œ ê°ì²´ íƒì§€
            results = yolo_model(frame)
            boxes = results.xyxy[0].cpu().numpy()

            infos = []
            detected = False
            
            for box in boxes:
                if len(box) < 6:
                    continue
                    
                x1, y1, x2, y2, conf, cls = box
                x1, y1, x2, y2 = map(int, (x1, y1, x2, y2))
                
                # ì‹ ë¢°ë„ê°€ ìµœì†Œ ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´ ë¬´ì‹œ
                if conf < self.min_detection_confidence:
                    continue
                
                # ê¹Šì´ ì •ë³´ ê³„ì‚°
                region = depth_map[y1:y2, x1:x2]
                if region.size > 0:
                    depth_val = float(np.median(region))
                else:
                    depth_val = 0.0

                # ê¹Šì´ ë¶„ë¥˜ ë° ìƒ‰ìƒ ê²°ì •
                depth_class, color = self._classify_depth(depth_val)
                color = tuple(color)

                # ì‹œê°í™”: ë°”ìš´ë”© ë°•ìŠ¤ì™€ ì‹ ë¢°ë„ í‘œì‹œ
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, self.box_thickness)
                cv2.putText(frame, f'Conf: {conf:.2f}', (x1, y1-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, self.text_size, color, self.text_thickness)
                
                # ê¹Šì´ ì •ë³´ í‘œì‹œ
                cv2.putText(frame, f'Depth: {depth_val:.1f} ({depth_class})', (x1, y1+20), 
                           cv2.FONT_HERSHEY_SIMPLEX, self.text_size, color, self.text_thickness)
                
                # í¬íŠ¸í™€ ì •ë³´ ì €ì¥
                pothole_info = {
                    "lat": self.default_lat,
                    "lng": self.default_lng,
                    "depth": round(depth_val, 2),
                    "confidence": float(conf),
                    "depth_class": depth_class,
                    "bbox": [x1, y1, x2, y2]
                }
                
                # ì¤‘ë³µ ê°ì§€ ì²´í¬ (ê°™ì€ í”„ë ˆì„ ë‚´ì—ì„œ)
                if not self._is_duplicate_detection([x1, y1, x2, y2]):
                    infos.append(pothole_info)
                    
                    # ìµœê·¼ ê°ì§€ ëª©ë¡ì— ì¶”ê°€ (ìºì‹œ í¬ê¸° ì œí•œ)
                    self.recent_detections.append(pothole_info)
                    if len(self.recent_detections) > 10:  # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
                        self.recent_detections.pop(0)
                
                # ì„œë²„ ì „ì†¡ ì„ê³„ê°’ ì´ìƒì´ë©´ ê°ì§€ë¨ìœ¼ë¡œ í‘œì‹œ
                if conf >= self.send_to_server_confidence:
                    detected = True
                    
                # ë””ë²„ê·¸ ì¶œë ¥
                if self.print_detections:
                    print(f"ê°ì§€: ì‹ ë¢°ë„={conf:.2f}, ê¹Šì´={depth_val:.1f}({depth_class})")

            return detected, infos, frame
            
        except Exception as e:
            print(f"âŒ í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False, [], frame
            
    def process_video_stream(self, source: Union[int, str] = 0, display: bool = True) -> None:
        """
        ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼(ì›¹ìº  ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼)ì—ì„œ í¬íŠ¸í™€ì„ ì‹¤ì‹œê°„ ê°ì§€í•©ë‹ˆë‹¤.
        
        Args:
            source: ë¹„ë””ì˜¤ ì†ŒìŠ¤ (0=ì›¹ìº , íŒŒì¼ ê²½ë¡œ=ë¹„ë””ì˜¤ íŒŒì¼)
            display: í™”ë©´ì— ê²°ê³¼ë¥¼ í‘œì‹œí• ì§€ ì—¬ë¶€
        """
        # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™”
        cap = cv2.VideoCapture(source)
        if not cap.isOpened():
            print(f"âŒ ë¹„ë””ì˜¤ ì†ŒìŠ¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source}")
            return
        
        # ë¹„ë””ì˜¤ ì„¤ì • ì ìš© (ì›¹ìº ì¸ ê²½ìš°)
        if isinstance(source, int):
            video_config = self.config.get('video', {})
            width = video_config.get('frame_width', 640)
            height = video_config.get('frame_height', 480)
            fps = video_config.get('fps', 30)
            
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            cap.set(cv2.CAP_PROP_FPS, fps)
            
            if self.print_model_loading:
                print(f"ğŸ“¹ ë¹„ë””ì˜¤ ì„¤ì • - í•´ìƒë„: {width}x{height}, FPS: {fps}")
            
        # ëª¨ë¸ ë¡œë“œ
        if not self.load_models():
            print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")
            cap.release()
            return
            
        print("ğŸ¯ ì‹¤ì‹œê°„ í¬íŠ¸í™€ ê°ì§€ ì‹œì‘...")
        print("ğŸ’¡ ì¢…ë£Œí•˜ë ¤ë©´ 'q' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”.")
        
        try:
            frame_count = 0
            while True:
                ret, frame = cap.read()
                if not ret:
                    print("âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    break
                    
                frame_count += 1
                
                # í”„ë ˆì„ì—ì„œ í¬íŠ¸í™€ ê°ì§€ ë° ì‹œê°í™”
                detected, pothole_infos, processed_frame = self.detect_from_frame(frame)
                
                # í¬íŠ¸í™€ì´ ê°ì§€ëœ ê²½ìš° ì„œë²„ë¡œ ì „ì†¡ ì—¬ë¶€ ê²°ì •
                if detected and pothole_infos:
                    should_send, selected_pothole = self._should_send_to_server(pothole_infos)
                    
                    if should_send and selected_pothole:
                        print(f"ğŸ•³ï¸  ìƒˆë¡œìš´ í¬íŠ¸í™€ ê°ì§€! ê¹Šì´: {selected_pothole['depth']}mm, " +
                              f"ì‹ ë¢°ë„: {selected_pothole['confidence']:.2f}, " +
                              f"ë¶„ë¥˜: {selected_pothole['depth_class']}")
                        
                        # ì„œë²„ë¡œ ì „ì†¡ (ì´ë¯¸ì§€ í¬í•¨)
                        success = self.server_api.send_pothole_data(
                            selected_pothole['lat'],
                            selected_pothole['lng'],
                            selected_pothole['depth'],
                            frame  # ì›ë³¸ í”„ë ˆì„ì„ í•¨ê»˜ ì „ì†¡
                        )
                        
                        if success:
                            # ì „ì†¡ ì„±ê³µ ì‹œ ìœ„ì¹˜ ìºì‹œì— ì¶”ê°€
                            self._add_sent_position(selected_pothole['lat'], selected_pothole['lng'])
                            self.last_send_time = time.time()
                            print(f"âœ… ì„œë²„ ì „ì†¡ ì™„ë£Œ")
                        else:
                            print(f"âŒ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨")
                    elif pothole_infos:
                        # ì „ì†¡í•˜ì§€ ì•Šì€ ì´ìœ  ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                        if self.print_detections:
                            print(f"ğŸ“ í¬íŠ¸í™€ ê°ì§€ë¨ (ì „ì†¡ ì•ˆí•¨): ì¤‘ë³µ ë˜ëŠ” ì‹œê°„ ê°„ê²© ë¯¸ì¶©ì¡±")
                
                # ì²˜ë¦¬ëœ í”„ë ˆì„ í‘œì‹œ
                if display:
                    # í”„ë ˆì„ ì •ë³´ í‘œì‹œ
                    cv2.putText(processed_frame, f'Frame: {frame_count}', (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                    
                    cv2.imshow('Porthole Detection System', processed_frame)
                    
                    # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q'):
                        print("ğŸ‘‹ ì‚¬ìš©ì ì¢…ë£Œ ìš”ì²­")
                        break
                        
        except KeyboardInterrupt:
            print("\nğŸ‘‹ í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ë¡œ ì¢…ë£Œ")
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        finally:
            cap.release()
            if display:
                cv2.destroyAllWindows()
            print("âœ… ì‹¤ì‹œê°„ í¬íŠ¸í™€ ê°ì§€ ì¢…ë£Œ")
